<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>OpenCV: Optical Flow</title>
<link href="opencv.ico" rel="shortcut icon" type="image/x-icon" />
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
//<![CDATA[
MathJax.Hub.Config(
{
  TeX: {
      Macros: {
          matTT: [ "\\[ \\left|\\begin{array}{ccc} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{array}\\right| \\]", 9],
          fork: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ \\end{array} \\right.", 4],
          forkthree: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ #5 & \\mbox{#6}\\\\ \\end{array} \\right.", 6],
          vecthree: ["\\begin{bmatrix} #1\\\\ #2\\\\ #3 \\end{bmatrix}", 3],
          vecthreethree: ["\\begin{bmatrix} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{bmatrix}", 9],
          hdotsfor: ["\\dots", 1],
          mathbbm: ["\\mathbb{#1}", 1],
          bordermatrix: ["\\matrix{#1}", 1]
      }
  }
}
);
//]]>
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<!--#include virtual="/google-search.html"-->
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="opencv-logo-small.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">OpenCV
   &#160;<span id="projectnumber">3.2.0-dev</span>
   </div>
   <div id="projectbrief">Open Source Computer Vision</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<script type="text/javascript">
//<![CDATA[
function getLabelName(innerHTML) {
    var str = innerHTML.toLowerCase();
    // Replace all '+' with 'p'
    str = str.split('+').join('p');
    // Replace all ' ' with '_'
    str = str.split(' ').join('_');
    // Replace all '#' with 'sharp'
    str = str.split('#').join('sharp');
    // Replace other special characters with 'ascii' + code
    for (var i = 0; i < str.length; i++) {
        var charCode = str.charCodeAt(i);
        if (!(charCode == 95 || (charCode > 96 && charCode < 123) || (charCode > 47 && charCode < 58)))
            str = str.substr(0, i) + 'ascii' + charCode + str.substr(i + 1);
    }
    return str;
}
function addToggle() {
    var $getDiv = $('div.newInnerHTML').last();
    var buttonName = $getDiv.html();
    var label = getLabelName(buttonName.trim());
    $getDiv.attr("title", label);
    $getDiv.hide();
    $getDiv = $getDiv.next();
    $getDiv.attr("class", "toggleable_div label_" + label);
    $getDiv.hide();
}
//]]>
</script>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="modules.html"><span>Modules</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="tutorial_js_root.html">OpenCV.js Tutorials</a></li><li class="navelem"><a class="el" href="tutorial_js_table_of_contents_video.html">Video Analysis</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Optical Flow </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Goal </h2>
<p>In this chapter,</p><ul>
<li>We will understand the concepts of optical flow and its estimation using Lucas-Kanade method.</li>
<li>We will use functions like <b><a class="el" href="dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323" title="Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with pyra...">cv.calcOpticalFlowPyrLK()</a></b> to track feature points in a video.</li>
</ul>
<h2>Optical Flow </h2>
<p>Optical flow is the pattern of apparent motion of image objects between two consecutive frames caused by the movemement of object or camera. It is 2D vector field where each vector is a displacement vector showing the movement of points from first frame to second. Consider the image below (Image Courtesy: <a href="http://en.wikipedia.org/wiki/Optical_flow">Wikipedia article on Optical Flow</a>).</p>
<div class="image">
<img src="optical_flow_basic1.jpg" alt="optical_flow_basic1.jpg"/>
<div class="caption">
image</div></div>
<p> It shows a ball moving in 5 consecutive frames. The arrow shows its displacement vector. Optical flow has many applications in areas like :</p>
<ul>
<li>Structure from Motion</li>
<li>Video Compression</li>
<li>Video Stabilization ...</li>
</ul>
<p>Optical flow works on several assumptions:</p>
<ol type="1">
<li>The pixel intensities of an object do not change between consecutive frames.</li>
<li>Neighbouring pixels have similar motion.</li>
</ol>
<p>Consider a pixel \(I(x,y,t)\) in first frame (Check a new dimension, time, is added here. Earlier we were working with images only, so no need of time). It moves by distance \((dx,dy)\) in next frame taken after \(dt\) time. So since those pixels are the same and intensity does not change, we can say,</p>
<p class="formulaDsp">
\[I(x,y,t) = I(x+dx, y+dy, t+dt)\]
</p>
<p>Then take taylor series approximation of right-hand side, remove common terms and divide by \(dt\) to get the following equation:</p>
<p class="formulaDsp">
\[f_x u + f_y v + f_t = 0 \;\]
</p>
<p>where:</p>
<p class="formulaDsp">
\[f_x = \frac{\partial f}{\partial x} \; ; \; f_y = \frac{\partial f}{\partial y}\]
</p>
 <p class="formulaDsp">
\[u = \frac{dx}{dt} \; ; \; v = \frac{dy}{dt}\]
</p>
<p>Above equation is called Optical Flow equation. In it, we can find \(f_x\) and \(f_y\), they are image gradients. Similarly \(f_t\) is the gradient along time. But \((u,v)\) is unknown. We cannot solve this one equation with two unknown variables. So several methods are provided to solve this problem and one of them is Lucas-Kanade.</p>
<h3>Lucas-Kanade method</h3>
<p>We have seen an assumption before, that all the neighbouring pixels will have similar motion. Lucas-Kanade method takes a 3x3 patch around the point. So all the 9 points have the same motion. We can find \((f_x, f_y, f_t)\) for these 9 points. So now our problem becomes solving 9 equations with two unknown variables which is over-determined. A better solution is obtained with least square fit method. Below is the final solution which is two equation-two unknown problem and solve to get the solution.</p>
<p class="formulaDsp">
\[\begin{bmatrix} u \\ v \end{bmatrix} = \begin{bmatrix} \sum_{i}{f_{x_i}}^2 &amp; \sum_{i}{f_{x_i} f_{y_i} } \\ \sum_{i}{f_{x_i} f_{y_i}} &amp; \sum_{i}{f_{y_i}}^2 \end{bmatrix}^{-1} \begin{bmatrix} - \sum_{i}{f_{x_i} f_{t_i}} \\ - \sum_{i}{f_{y_i} f_{t_i}} \end{bmatrix}\]
</p>
<p>( Check similarity of inverse matrix with Harris corner detector. It denotes that corners are better points to be tracked.)</p>
<p>So from user point of view, idea is simple, we give some points to track, we receive the optical flow vectors of those points. But again there are some problems. Until now, we were dealing with small motions. So it fails when there is large motion. So again we go for pyramids. When we go up in the pyramid, small motions are removed and large motions becomes small motions. So applying Lucas-Kanade there, we get optical flow along with the scale.</p>
<h2>Lucas-Kanade Optical Flow in OpenCV </h2>
<p>OpenCV provides all these in a single function, <b><a class="el" href="dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323" title="Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with pyra...">cv.calcOpticalFlowPyrLK()</a></b>. Here, we create a simple application which tracks some points in a video. To decide the points, we use <b><a class="el" href="dd/d1a/group__imgproc__feature.html#ga1d6bb77486c8f92d79c8793ad995d541" title="Determines strong corners on an image. ">cv.goodFeaturesToTrack()</a></b>. We take the first frame, detect some Shi-Tomasi corner points in it, then we iteratively track those points using Lucas-Kanade optical flow. For the function <b><a class="el" href="dc/d6b/group__video__track.html#ga473e4b886d0bcc6b65831eb88ed93323" title="Calculates an optical flow for a sparse feature set using the iterative Lucas-Kanade method with pyra...">cv.calcOpticalFlowPyrLK()</a></b> we pass the previous frame, previous points and next frame. It returns next points along with some status numbers which has a value of 1 if next point is found, else zero. We iteratively pass these next points as previous points in next step. See the code demo below.</p>
<h3>Try it</h3>
<p>Here is the demo. Some core code is in the textbox, and you can click <code>try it</code> to investigate more.</p>
<p> 
<head>
<style>
canvas {
    border: 1px solid black;
}
.err {
    color: red;
}
</style>
</head>
<body>

<div id="CodeArea">
<h3>Input your code</h3>
<textarea rows="30" cols="90" id="lkofTestCode" spellcheck="false">
// Mats used in the loop are all declared and deleted elsewhere
//  params for ShiTomasi corner detection
let [maxCorners, qualityLevel, minDistance, blockSize] = [30, 0.3, 7, 7];

// Parameters for lucas kanade optical flow
let winSize  = [15,15];
let maxLevel = 2;
let criteria = new cv.TermCriteria(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03);

// Create some random colors
color = [];
for(let i = 0; i < maxCorners; i++)
    color.push(new cv.Scalar(parseInt(Math.random()*255), parseInt(Math.random()*255), parseInt(Math.random()*255), 255));

// Take first frame and find corners in it
let oldFrame = new cv.Mat(lkofHeight, lkofWidth, cv.CV_8UC4);
context.drawImage(lkofVideo, 0, 0, lkofWidth, lkofHeight);
oldFrame.data().set(context.getImageData(0, 0, lkofWidth, lkofHeight).data);
oldGray = new cv.Mat();
cv.cvtColor(oldFrame, oldGray, cv.COLOR_RGB2GRAY);
p0 = new cv.Mat();
let none = new cv.Mat();
cv.goodFeaturesToTrack(oldGray, p0, maxCorners, qualityLevel, minDistance, none, blockSize);

// Create a mask image for drawing purposes
let zeroEle = new cv.Scalar(0, 0, 0, 255);
mask = new cv.Mat(oldFrame.rows, oldFrame.cols, oldFrame.type(), zeroEle);

frame = new cv.Mat(lkofHeight, lkofWidth, cv.CV_8UC4);
frameGray = new cv.Mat();
p1 = new cv.Mat();
st = new cv.Mat();
err = new cv.Mat();
lkofLoopIndex = setInterval(
    function() {
        if(lkofVideo.ended) lkofStopVideo();
        context.drawImage(lkofVideo, 0, 0, lkofWidth, lkofHeight);
        frame.data().set(context.getImageData(0, 0, lkofWidth, lkofHeight).data);
        cv.cvtColor(frame, frameGray, cv.COLOR_RGBA2GRAY);

        // calculate optical flow
        cv.calcOpticalFlowPyrLK(oldGray, frameGray, p0, p1, st, err, winSize, maxLevel, criteria);

        // Select good points
        let goodNew = [];
        let goodOld = [];
        for(let i = 0; i < st.rows; i++) {
            if(st.data()[i] === 1) {
                goodNew.push([p1.data32f()[i*2], p1.data32f()[i*2+1]]);
                goodOld.push([p0.data32f()[i*2], p0.data32f()[i*2+1]]);
            }
        }

        // draw the tracks
        for(let i = 0; i < goodNew.length; i++) {
            cv.line(mask, goodNew[i], goodOld[i], color[i], 2);
            cv.circle(frame, goodNew[i], 5, color[i],-1);
        }
        cv.add(frame, mask, frame);

        cv.imshow("lkofCanvasOutput", frame);

        // Now update the previous frame and previous points
        frameGray.copyTo(oldGray);
        p0.delete(); p0 = null;
        p0 = new cv.Mat(goodNew.length, 1, cv.CV_32FC2);
        for(let i = 0; i < goodNew.length; i++) {
            p0.data32f()[i*2] = goodNew[i][0];
            p0.data32f()[i*2+1] = goodNew[i][1];
        }
    }, 33); 
</textarea>
<p class="err" id="lkofErr"></p>
</div> 
<canvas id="lkofCanvasFrame" hidden></canvas>
<div id="contentarea">
    <button id="lkofStartup" disabled="true" onclick="lkofStartup()">try it</button>
    <button id="lkofStop" disabled="true" onclick="lkofStopVideo()">stop</button><br>
    <video id="lkofVideo" src="box.mp4" width="640" muted hidden>Your browser does not support the video tag.</video>
    <canvas id="lkofCanvasOutput"></canvas>
</div>
<script src="adapter.js"></script>
<script src="utils.js"></script>
<script async src="opencv.js" id="opencvjs"></script>
<script>
// lkof means Lucas-Kanade Optical Flow
// Some HTML elements we need to configure.
let lkofVideo = document.getElementById("lkofVideo");
let lkofCanvasFrame = document.getElementById("lkofCanvasFrame");
let lkofStop = document.getElementById("lkofStop");

// In this case, We set width 640, and the height will be computed based on the input video.
let lkofWidth = lkofVideo.width;
let lkofHeight = null;
let lkofLoopIndex = null;
let frame = null;
let oldGray = null;
let frameGray = null;
let p0 = null;
let p1 = null;
let st = null;
let err = null;
let mask = null;
let color = null;

lkofVideo.oncanplay = function() {
    lkofVideo.setAttribute("height", lkofVideo.videoHeight/lkofVideo.videoWidth*lkofVideo.width);
    lkofHeight = lkofVideo.height;
    lkofCanvasFrame.setAttribute("width", lkofWidth);
    lkofCanvasFrame.setAttribute("height", lkofHeight);
};

lkofVideo.onended = lkofStopVideo;

function lkofStartup() {
    if(lkofVideo.readyState !== 4)
        lkofVideo.load();
    lkofVideo.play();
    lkofStop.disabled = false;
    let context = lkofCanvasFrame.getContext("2d");

    let lkofTestCode = document.getElementById("lkofTestCode").value;
    try {
        eval(lkofTestCode);
        document.getElementById("lkofErr").innerHTML = " ";
    } catch(err) {
        document.getElementById("lkofErr").innerHTML = err;
    }   
    document.getElementById("lkofStartup").disabled = true;
}

function lkofStopVideo() {
    clearInterval(lkofLoopIndex);
    if (frame != null && !frame.isDeleted()) {
        frame.delete();
        frame = null;
    }
    if (oldGray != null && !oldGray.isDeleted()) {
        oldGray.delete();
        oldGray = null;
    }
    if (frameGray != null && !frameGray.isDeleted()) {
        frameGray.delete();
        frameGray = null;
    }
    if (p0 != null && !p0.isDeleted()) {
        p0.delete();
        p0 = null;
    }
    if (p1 != null && !p1.isDeleted()) {
        p1.delete();
        p1 = null;
    }
    if (st != null && !st.isDeleted()) {
        st.delete();
        st = null;
    }
    if (err != null && !err.isDeleted()) {
        err.delete();
        err = null;
    }
    if (mask != null && !mask.isDeleted()) {
        mask.delete();
        mask = null;
    }
    if (color != null && color.length > 0 && !color[0].isDeleted()) {
        for(let i = 0; i < color.length; i++)
            color[i].delete();
        color = null;
    }
    //document.getElementById("lkofCanvasOutput").getContext("2d").clearRect(0, 0, lkofWidth, lkofHeight);
    lkofVideo.pause();
    lkofVideo.currentTime = 0;
    document.getElementById("lkofStartup").disabled = false;
}
</script>
</body>
</p>
<p>(This code doesn't check how correct are the next keypoints. So even if any feature point disappears in image, there is a chance that optical flow finds the next point which may look close to it. So actually for a robust tracking, corner points should be detected in particular intervals.)</p>
<h2>Dense Optical Flow in OpenCV </h2>
<p>Lucas-Kanade method computes optical flow for a sparse feature set (in our example, corners detected using Shi-Tomasi algorithm). OpenCV provides another algorithm to find the dense optical flow. It computes the optical flow for all the points in the frame. It is based on Gunner Farneback's algorithm which is explained in "Two-Frame Motion Estimation Based on Polynomial Expansion" by Gunner Farneback in 2003.</p>
<p>Below sample shows how to find the dense optical flow using above algorithm, and the function is <b><a class="el" href="dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af" title="Computes a dense optical flow using the Gunnar Farneback&#39;s algorithm. ">cv.calcOpticalFlowFarneback()</a></b>. We get a 2-channel array with optical flow vectors, \((u,v)\). We find their magnitude and direction. We color code the result for better visualization. Direction corresponds to Hue value of the image. Magnitude corresponds to Value plane. See the code demo below.</p>
<h3>Try it</h3>
<p>Here is the demo. Some core code is in the textbox, and you can click <code>try it</code> to investigate more.</p>
<p> 
<head>
<style>
video {
    border: 1px solid black;
}
canvas {
    border: 1px solid black;
}
.err {
    color: red;
}
</style>
</head>
<body>

<div id="CodeArea">
<h3>Input your code</h3>
<textarea rows="30" cols="90" id="dofTestCode" spellcheck="false">
// Mats used in the loop are all declared and deleted elsewhere
// take first frame of the video
let frame1 = new cv.Mat(dofHeight, dofWidth, cv.CV_8UC4);
context.drawImage(dofVideo, 0, 0, dofWidth, dofHeight);
frame1.data().set(context.getImageData(0, 0, dofWidth, dofHeight).data);

prvs = new cv.Mat();
cv.cvtColor(frame1, prvs, cv.COLOR_RGBA2GRAY);
frame1.delete();
hsv = new cv.Mat();
hsv0 = new cv.Mat(dofHeight, dofWidth, cv.CV_8UC1);
let sValue = new cv.Scalar(255)
hsv1 = new cv.Mat(dofHeight, dofWidth, cv.CV_8UC1, sValue);
sValue.delete();
hsv2 = new cv.Mat(dofHeight, dofWidth, cv.CV_8UC1);
hsvVec = new cv.MatVector();
hsvVec.push_back(hsv0); hsvVec.push_back(hsv1); hsvVec.push_back(hsv2);

frame2 = new cv.Mat(dofHeight, dofWidth, cv.CV_8UC4);
next = new cv.Mat(dofHeight, dofWidth, cv.CV_8UC1);
flow = new cv.Mat(dofHeight, dofWidth, cv.CV_32FC2);
flowVec = new cv.MatVector();
mag = new cv.Mat(dofHeight, dofWidth, cv.CV_32FC1);
ang = new cv.Mat(dofHeight, dofWidth, cv.CV_32FC1);
rgb = new cv.Mat(dofHeight, dofWidth, cv.CV_8UC3);
dofLoopIndex = setInterval(
    function() {
        if(dofVideo.ended) dofStopVideo();
        context.drawImage(dofVideo, 0, 0, dofWidth, dofHeight);
        frame2.data().set(context.getImageData(0, 0, dofWidth, dofHeight).data);
        cv.cvtColor(frame2, next, cv.COLOR_RGBA2GRAY);
        cv.calcOpticalFlowFarneback(prvs, next, flow, 0.5, 3, 15, 3, 5, 1.2, 0)
        cv.split(flow, flowVec);
        cv.cartToPolar(flowVec.get(0), flowVec.get(1), mag, ang);
        ang.convertTo(hsv0, cv.CV_8UC1, 180/Math.PI/2);
        cv.normalize(mag, hsv2, 0, 255, cv.NORM_MINMAX, cv.CV_8UC1);
        hsvVec.set(0, hsv0); hsvVec.set(1, hsv1); hsvVec.set(2, hsv2);
        cv.merge(hsvVec, hsv);
        cv.cvtColor(hsv, rgb, cv.COLOR_HSV2RGB);
        cv.imshow("dofCanvasOutput", rgb);
        next.copyTo(prvs);
    }, 33);    
</textarea>
<p class="err" id="dofErr"></p>
</div>
<canvas id="dofCanvasFrame" hidden></canvas>
<div id="contentarea">
    <button id="dofStartup" disabled="true" onclick="dofStartup()">try it</button>
    <button id="dofStop" disabled="true" onclick="dofStopVideo()">stop</button><br>
    <video id="dofVideo" src="box.mp4" width="320" muted>Your browser does not support the video tag.</video>
    <canvas id="dofCanvasOutput"></canvas>
</div>
<script>
// dof means Dense Optical Flow
// Some HTML elements we need to configure.
let dofVideo = document.getElementById("dofVideo");
let dofCanvasFrame = document.getElementById("dofCanvasFrame");
let dofStop = document.getElementById("dofStop");

// In this case, We set width 320, and the height will be computed based on the input video.
let dofWidth = dofVideo.width;
let dofHeight = null;
let dofLoopIndex = null;
let prvs = null;
let hsv = null;
let hsv0 = null;
let hsv1 = null;
let hsv2 = null;
let hsvVec = null;
let frame2 = null;
let next = null;
let flow = null;
let flowVec = null;
let mag = null;
let ang = null;
let rgb = null;

dofVideo.oncanplay = function() {
    dofVideo.setAttribute("height", dofVideo.videoHeight/dofVideo.videoWidth*dofVideo.width);
    dofHeight = dofVideo.height;
    dofCanvasFrame.setAttribute("width", dofWidth);
    dofCanvasFrame.setAttribute("height", dofHeight);
};

dofVideo.onended = dofStopVideo;

function dofStartup() {
    if(dofVideo.readyState !== 4)
        dofVideo.load();
    dofVideo.play();
    dofStop.disabled = false;
    let context = dofCanvasFrame.getContext("2d");
    let dofTestCode = document.getElementById("dofTestCode").value;

    try {
        eval(dofTestCode);
        document.getElementById("dofErr").innerHTML = " ";
    } catch(err) {
        document.getElementById("dofErr").innerHTML = err;
    }
    document.getElementById("dofStartup").disabled = true;
}

function dofStopVideo() {
    clearInterval(dofLoopIndex);
    if (prvs != null && !prvs.isDeleted()) {
        prvs.delete();
        prvs = null;
    }
    if (hsv != null && !hsv.isDeleted()) {
        hsv.delete();
        hsv = null;
    }
    if (hsv0 != null && !hsv0.isDeleted()) {
        hsv0.delete();
        hsv0 = null;
    }
    if (hsv1 != null && !hsv1.isDeleted()) {
        hsv1.delete();
        hsv1 = null;
    }
    if (hsv2 != null && !hsv2.isDeleted()) {
        hsv2.delete();
        hsv2 = null;
    }
    if (hsvVec != null && !hsvVec.isDeleted()) {
        hsvVec.delete();
        hsvVec = null;
    }
    if (frame2 != null && !frame2.isDeleted()) {
        frame2.delete();
        frame2 = null;
    }
    if (flow != null && !flow.isDeleted()) {
        flow.delete();
        flow = null;
    }
    if (flowVec != null && !flowVec.isDeleted()) {
        flowVec.delete();
        flowVec = null;
    }
    if (next != null && !next.isDeleted()) {
        next.delete();
        next = null;
    }
    if (mag != null && !mag.isDeleted()) {
        mag.delete();
        mag = null;
    }
    if (ang != null && !ang.isDeleted()) {
        ang.delete();
        ang = null;
    }
    if (rgb != null && !rgb.isDeleted()) {
        rgb.delete();
        rgb = null;
    }
    //document.getElementById("dofCanvasOutput").getContext("2d").clearRect(0, 0, dofWidth, dofHeight);
    dofVideo.pause();
    dofVideo.currentTime = 0;
    document.getElementById("dofStartup").disabled = false;
}


function onReady() {
    document.getElementById("lkofStartup").disabled = false;
    document.getElementById("dofStartup").disabled = false;
}
if (typeof cv !== 'undefined') {
    onReady();
} else {
    document.getElementById("opencvjs").onload = onReady;
}
</script>
</body>
 </p>
</div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.6-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Thu Aug 3 2017 09:58:30 for OpenCV by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
<script type="text/javascript">
//<![CDATA[
function addButton(label, buttonName) {
    var b = document.createElement("BUTTON");
    b.innerHTML = buttonName;
    b.setAttribute('class', 'toggleable_button label_' + label);
    b.onclick = function() {
        $('.toggleable_button').css({
            border: '2px outset',
            'border-radius': '4px'
        });
        $('.toggleable_button.label_' + label).css({
            border: '2px inset',
            'border-radius': '4px'
        });
        $('.toggleable_div').css('display', 'none');
        $('.toggleable_div.label_' + label).css('display', 'block');
    };
    b.style.border = '2px outset';
    b.style.borderRadius = '4px';
    b.style.margin = '2px';
    return b;
}
function buttonsToAdd($elements, $heading, $type) {
    if ($elements.length === 0) {
        $elements = $("" + $type + ":contains(" + $heading.html() + ")").parent().prev("div.newInnerHTML");
    }
    var arr = jQuery.makeArray($elements);
    var seen = {};
    arr.forEach(function(e) {
        var txt = e.innerHTML;
        if (!seen[txt]) {
            $button = addButton(e.title, txt);
            if (Object.keys(seen).length == 0) {
                var linebreak1 = document.createElement("br");
                var linebreak2 = document.createElement("br");
                ($heading).append(linebreak1);
                ($heading).append(linebreak2);
            }
            ($heading).append($button);
            seen[txt] = true;
        }
    });
    return;
}
$("h2").each(function() {
    $heading = $(this);
    $smallerHeadings = $(this).nextUntil("h2").filter("h3").add($(this).nextUntil("h2").find("h3"));
    if ($smallerHeadings.length) {
        $smallerHeadings.each(function() {
            var $elements = $(this).nextUntil("h3").filter("div.newInnerHTML");
            buttonsToAdd($elements, $(this), "h3");
        });
    } else {
        var $elements = $(this).nextUntil("h2").filter("div.newInnerHTML");
        buttonsToAdd($elements, $heading, "h2");
    }
});
$(".toggleable_button").first().click();
var $clickDefault = $('.toggleable_button.label_python').first();
if ($clickDefault.length) {
    $clickDefault.click();
}
$clickDefault = $('.toggleable_button.label_cpp').first();
if ($clickDefault.length) {
    $clickDefault.click();
}
//]]>
</script>
</body>
</html>
